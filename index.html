
<!doctype html>
<meta charset=utf-8>
<title>Infinite Nature: Perpetual View Generation of Natural Scenes from a Single Image</title>
<style>
body {
  margin: 0 auto;
  padding: 30px 14px 50px;
  font-family: sans-serif;
  background: #f3f3f3;
  color: #222;
  max-width: 800px;
}
p {
  line-height: 150%;
  max-width: 45em;
}
h1, h2 {
  font-weight: 200;
}
h2 a {
  color: #000;
}

h3 {
  margin-top: 40px;
}
a {
  text-decoration: none;
  color: #22b;
}
a:hover {
  text-decoration: underline;
  color: #22b;
}
a:hover img {
  opacity: .5;
}
.paper img { background: #888; }
.video img {
  border-radius: 6px;
  background: #000;
}
h1 span {
  font-size: 90%;
  line-height: 1.5em;
}
h1 span::before { content: "("; }
h1 span::after { content: ")"; }
h1 span::before, h1 span::after {
  vertical-align: .06em;
}
h2 span {
  line-height: 2em;
}
em {
  color: #333;
  font-weight: bold;
  font-style: normal;
}
.teaser {
  max-width: 45em;
  margin: 40px 0 60px 0;
  white-space: nowrap;
  position: relative;
}
.teaser .imgs .full {
  width: 100%;
}
.teaser .imgs .center {
  position: absolute;
  width: 32%;
  top: -3%;
  left: 34%;
}
.teaser .labels span {
  display: inline-block;
  width: 33%;
  text-align: center;
  padding-top: 10px;
}
.bibtex {
  white-space: pre;
  font-family: monospace;
  line-height: 150%;
  background: #fff;
  padding: 10px;
  display: inline-block;
  border-radius: 4px;
}
.crow > * {
  vertical-align: middle;
  margin-right: 14px;
}
a.img {
  display: inline-block;
}
.links {
  display: inline-block;
  line-height: 150%;
  padding: 8px 0;
}
.links a {
  padding: 0 3px;
}
.examples {
  padding: 10px 0;
  max-width: 50em;
}
.examples img {
  display: inline-block;
  width: 192px;
  height: 108px;
}

</style>
<h1 align="center">Infinite Nature: Perpetual View Generation of Natural Scenes from a Single Image</h1><br>
<table align=center width=100%>
<tr>
  <td align=center width=100px>
     <span style="font-size:15px"><a href="">Andrew Liu</a><sup>*</sup></span>
   </td>
  <td align=center width=100px>
    <span style="font-size:15px"><a href="">Richard Tucker</a><sup>*</sup></span>
  </td>
  <td align=center width=100px>
    <span style="font-size:15px"><a href="">Varun Jumpani</a></span>
  </td>
  <td align=center width=100px>
    <span style="font-size:15px"><a href="">Ameesh Makadia</a></span>
  </td>
  <td align=center width=100px>
    <span style="font-size:15px"><a href="">Noah Snavely</a></span>
  </td>
  <td align=center width=100px>
    <span style="font-size:15px"><a href="">Angjoo Kanazawa</a></span>
  </td>
</tr>
</table>
<h5 align=center style="font-size:14px;font-weight:normal" >Google Research</h5>
<hr>

<div align="center">
  <video autoplay loop muted playsinline width="30%">
    <source src="animation0.mp4" type="video/mp4">
  </video>
  <video autoplay loop muted playsinline width="30%">
    <source src="animation1.mp4" type="video/mp4">
  </video>
  <video autoplay loop muted playsinline width="30%">
    <source src="animation2.mp4" type="video/mp4">
  </video>
  <br>
  <video autoplay loop muted playsinline width="30%">
    <source src="animation3.mp4" type="video/mp4">
  </video>
  <video autoplay loop muted playsinline width="30%">
    <source src="animation4.mp4" type="video/mp4">
  </video>
</div>

<h3>Abstract</h3>
<p align="justify">We introduce the problem of <i>perpetual view generation</i>&mdash;long-range generation of novel views 
  corresponding to an arbitrarily long camera trajectory given a single image. This is a 
  challenging problem that goes far beyond the capabilities of current view synthesis methods, 
  which work for a limited range of viewpoints and quickly degenerate when presented with a 
  large camera motion. Methods designed for video generation also have limited ability to produce 
  long video sequences and are often agnostic to scene geometry. We take a hybrid approach that 
  integrates both geometry and image synthesis in an iterative <i>render</i>, <i>refine</i>, and <i>repeat</i> framework, 
  allowing for long-range generation that cover large distances after hundreds of frames. Our approach 
  can be trained from a set of monocular video sequences without any manual annotation. We propose a 
  dataset of aerial footage of natural coastal scenes, and compare our method with recent view synthesis 
  and conditional video generation baselines, showing that it can generate plausible scenes for much 
  longer time horizons over large camera trajectories compared to existing methods.
</p>

<h3>Paper</h3>
<div class=crow>
<a class=img href="inf_nat_arxiv.pdf"><img src="inf_nat_first_page.png" height=150 style="border: 1px solid transparent"></a>
<div class=links>
<em>Infinite Nature: Perpetual View Generation of Natural Scenes from Single Images</em><br>
Andrew Liu*, Richard Tucker*, Varun Jampani,<br>
Ameesh Makadia, Noah Snavely, Angjoo Kanazawa<br><br>
arXiv<br>
[<a href="inf_nat_arxiv.pdf">PDF</a>] [<a href="">Arxiv</a>]
</div>
</div>

<h3>Video</h3>

<p>Coming Soon</p>

<div class=crow>
<a class=img href="https://youtu.be/oXUf6anNAtc"><img src="vid.png" style="border-radius: 6px; border: 1px solid #444;" width=450></a>
<div class=links>
[<a href="https://youtu.be/XOYE-OkjVSI">YouTube</a>]
</div>
</div>

<h3>Code</h3>
<p>Coming Soon</p>


<h3>Aerial Coastline Imagery Dataset</h3>
<p>Coming Soon</p>

<h3>BibTeX</h3>
<div class=bibtex>@InProceedings{infinite_nature_2020,
  author = {Liu, Andrew and Tucker, Richard and Jampani, Varun and Makadia, Ameesh and Snavely, Noah and Kanazawa, Angjoo},
  title = {Infinite Nature: Perpetual View Generation of Natural Scenes from Single Images},
  booktitle = {arXiv},
  month = {December},
  year = {2020}
}
</div>

